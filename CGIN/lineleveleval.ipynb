{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import get_classification_model\n",
    "from torch_geometric.data import Data\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_GIN_CLASSIFIER = {\n",
    "    \"type\": \"GraphClassifier\",\n",
    "    \"name\": \"BASELINE_GIN\",\n",
    "    \"encoder\": {\n",
    "        \"type\": \"GraphComposite\",\n",
    "        \"pooling\": {\n",
    "            \"type\": \"sum\"\n",
    "        },\n",
    "        \"encoder\": {\n",
    "            \"num_layers\": 3,\n",
    "            \"hidden_channels\": 128,\n",
    "            \"layer_type\": \"CGIN\",\n",
    "            \"norm_type\": \"None\",\n",
    "\n",
    "        }\n",
    "    },\n",
    "    \"classifier\": {\n",
    "        \"layer_type\": \"MLP\",\n",
    "        \"dropout\": 0.5,\n",
    "        \"num_layers\": 3\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_GIN_CLASSIFIER[\"features\"] = 150\n",
    "BASELINE_GIN_CLASSIFIER[\"classes\"] = 1\n",
    "model = get_classification_model(BASELINE_GIN_CLASSIFIER).encoder.node_level_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"14_model.chkpt\"))\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222262"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18864it [00:22, 849.48it/s] \n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "csv.field_size_limit(1000000000)\n",
    "groundtruth = {}\n",
    "with open(\"../test.csv\", 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in tqdm(reader):\n",
    "            if row[\"target\"] == \"0\":\n",
    "                continue\n",
    "            if row[\"flaw_line\"] is None:\n",
    "                 continue\n",
    "            groundtruth[row[\"index\"]] = row[\"flaw_line\"].split(\"/~/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "@torch.no_grad()\n",
    "def sort_lines(scores):\n",
    "    _, indices = torch.sort(torch.as_tensor(scores), descending=True)\n",
    "    return indices.tolist()\n",
    "\n",
    "\n",
    "def get_flaw_indices(lines, flaw_lines):\n",
    "    indices = []\n",
    "    def clean(line):\n",
    "        # line = re.sub(\"^\\s\", \"\", line)\n",
    "        # line = re.sub(\"\\s$\", \"\", line)\n",
    "        line = re.sub(\"\\s\", \"\", line)\n",
    "        return line\n",
    "    flaw_lines = [clean(flaw_line) for flaw_line in flaw_lines if len(clean(flaw_line)) != 0]\n",
    "    lines = [clean(line) for line in lines]\n",
    "\n",
    "    for i, line in enumerate(lines):\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        if any(line in flaw_line for flaw_line in flaw_lines) or \\\n",
    "            any(flaw_line in line for flaw_line in flaw_lines):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def min_rank_of_indices(sorted_indices, searched_indices):\n",
    "    rank_mapping = {index: rank for rank, index in enumerate(sorted_indices)}\n",
    "    return min(\n",
    "        (rank_mapping[index] for index in searched_indices if index in rank_mapping),\n",
    "        default=float(\"inf\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_lines(idx, set=\"test\"):\n",
    "    with open(f\"../data/test/{set}/{idx}_1.c\", \"r\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_linelevel(CPG_SET, C_SET):\n",
    "    ranks = []\n",
    "    successful_idxs = []\n",
    "    print(f\"Evaluating {CPG_SET}\")\n",
    "    for name in tqdm(list(glob.glob(f\"../cache/{CPG_SET}/*_1*\"))):\n",
    "        idx = name.split(\"/\")[-1].split(\"_\")[0]\n",
    "        if idx not in groundtruth:\n",
    "            continue\n",
    "\n",
    "        c_lines = get_c_lines(idx, C_SET)\n",
    "        flaw_indices = get_flaw_indices(c_lines, groundtruth[idx])\n",
    "        if len(flaw_indices) < 1:\n",
    "            continue\n",
    "\n",
    "        object_file = pickle.load(gzip.open(name))\n",
    "        data = Data(x=torch.cat((object_file[\"astenc\"], object_file[\"codeenc\"]), dim=1), edge_index=object_file[\"edge_index\"], y=object_file[\"y\"])\n",
    "        data.edge_index = data.edge_index.long()\n",
    "        data.x = data.x.float()\n",
    "        c_logs, o_logs, co_logs = model(data)\n",
    "\n",
    "        edge_c, edge_t, node_c, node_t = model.layer.explain(data)\n",
    "        node_mask = node_c.sigmoid()\n",
    "\n",
    "        linescores = defaultdict(int)\n",
    "        for node_idx, score in enumerate(node_mask):\n",
    "            if \":\" not in object_file[\"lines\"][node_idx]:\n",
    "                continue\n",
    "            lower = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[0].replace(\"\\\"\",\"\"))\n",
    "            upper = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[1].replace(\"\\\"\",\"\"))\n",
    "            lines = list(range(int(lower), int(upper)+1))\n",
    "            for line in lines:\n",
    "                linescores[line] += score/len(lines)\n",
    "        lines = [0 for _ in range(max(linescores.keys()))]\n",
    "        for line, score in linescores.items():\n",
    "            lines[line-1] = score\n",
    "        \n",
    "        sorted_lines = sort_lines(lines)\n",
    "        rank = min_rank_of_indices(sorted_lines, flaw_indices)\n",
    "        ranks.append(rank)\n",
    "        if torch.as_tensor(rank).isfinite():\n",
    "            successful_idxs.append(idx)\n",
    "    ranks = torch.as_tensor(ranks)\n",
    "    ranks = ranks[ranks.isfinite()]\n",
    "    print({\n",
    "        \"Top1-Acc\": torch.sum(ranks < 1) / len(ranks),\n",
    "        \"Top5-Acc\": torch.sum(ranks < 5) / len(ranks),\n",
    "        \"Top10-Acc\": torch.sum(ranks < 10) / len(ranks),\n",
    "        \"Top100-Acc\": torch.sum(ranks < 100) / len(ranks),\n",
    "        \"IFA\": torch.mean(ranks),\n",
    "        \"Count\": len(ranks),\n",
    "    })\n",
    "    with open(f\"scuccessful_idxs/{CPG_SET}_successful.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(successful_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_TEST\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 593/593 [00:25<00:00, 22.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.2970), 'Top5-Acc': tensor(0.5916), 'Top10-Acc': tensor(0.7285), 'Top100-Acc': tensor(0.9768), 'IFA': tensor(12.3949), 'Count': 431}\n",
      "{'Top1-Acc': tensor(0.2991), 'Top5-Acc': tensor(0.5958), 'Top10-Acc': tensor(0.7336), 'Top100-Acc': tensor(0.9836), 'IFA': tensor(12.3949), 'Count': 428}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_TEST\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_CHROMIUM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [00:23<00:00, 24.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.2401), 'Top5-Acc': tensor(0.5289), 'Top10-Acc': tensor(0.6778), 'Top100-Acc': tensor(0.9574), 'IFA': tensor(16.6440), 'Count': 329}\n",
      "{'Top1-Acc': tensor(0.2446), 'Top5-Acc': tensor(0.5387), 'Top10-Acc': tensor(0.6904), 'Top100-Acc': tensor(0.9752), 'IFA': tensor(16.6440), 'Count': 323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_CHROMIUM\", \"apply_codestyle_Chromium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_GNU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:29<00:00, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.0891), 'Top5-Acc': tensor(0.3217), 'Top10-Acc': tensor(0.5039), 'Top100-Acc': tensor(0.9070), 'IFA': tensor(28.7391), 'Count': 258}\n",
      "{'Top1-Acc': tensor(0.0909), 'Top5-Acc': tensor(0.3281), 'Top10-Acc': tensor(0.5138), 'Top100-Acc': tensor(0.9249), 'IFA': tensor(28.7391), 'Count': 253}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_GNU\", \"apply_codestyle_GNU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_GOOGLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [00:26<00:00, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.2266), 'Top5-Acc': tensor(0.5529), 'Top10-Acc': tensor(0.7009), 'Top100-Acc': tensor(0.9637), 'IFA': tensor(15.3252), 'Count': 331}\n",
      "{'Top1-Acc': tensor(0.2301), 'Top5-Acc': tensor(0.5613), 'Top10-Acc': tensor(0.7117), 'Top100-Acc': tensor(0.9785), 'IFA': tensor(15.3252), 'Count': 326}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_GOOGLE\", \"apply_codestyle_Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_LLVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 596/596 [00:28<00:00, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.2478), 'Top5-Acc': tensor(0.5373), 'Top10-Acc': tensor(0.6866), 'Top100-Acc': tensor(0.9612), 'IFA': tensor(15.7182), 'Count': 335}\n",
      "{'Top1-Acc': tensor(0.2515), 'Top5-Acc': tensor(0.5455), 'Top10-Acc': tensor(0.6970), 'Top100-Acc': tensor(0.9758), 'IFA': tensor(15.7182), 'Count': 330}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_LLVM\", \"apply_codestyle_LLVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_MOZILLA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [00:30<00:00, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': tensor(0.2212), 'Top5-Acc': tensor(0.4985), 'Top10-Acc': tensor(0.6342), 'Top100-Acc': tensor(0.9499), 'IFA': tensor(19.4187), 'Count': 339}\n",
      "{'Top1-Acc': tensor(0.2259), 'Top5-Acc': tensor(0.5090), 'Top10-Acc': tensor(0.6476), 'Top100-Acc': tensor(0.9699), 'IFA': tensor(19.4187), 'Count': 332}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel(\"LINEVUL_MOZILLA\", \"apply_codestyle_Mozilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n"
     ]
    }
   ],
   "source": [
    "# merge successful idxs\n",
    "merged = None\n",
    "for path in glob.glob(\"successful_idxs/*.txt\"):\n",
    "    if \"merged\" in path:\n",
    "        continue\n",
    "    with open(path, \"r\") as f:\n",
    "        content = f.read()\n",
    "    content = content.split(\"\\n\")\n",
    "    if merged is None:\n",
    "        merged = set(map(int, content))\n",
    "    merged &= set(map(int, content))\n",
    "with open(\"successful_idxs/merged.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(map(str, merged)))\n",
    "print(len(merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_linelevel_merged(CPG_SET, C_SET):\n",
    "    ranks = []\n",
    "    with open(\"successful_idxs/merged.txt\", \"r\") as f:\n",
    "        successful_idxs = set(f.read().split(\"\\n\"))\n",
    "    print(f\"Evaluating {CPG_SET}\")\n",
    "    for name in list(map(lambda idx: f\"../cache/{CPG_SET}/{idx}_1.cpg.pt.gz\", successful_idxs)):\n",
    "        idx = name.split(\"/\")[-1].split(\"_\")[0]\n",
    "        if idx not in groundtruth:\n",
    "            continue\n",
    "\n",
    "        c_lines = get_c_lines(idx, C_SET)\n",
    "        flaw_indices = get_flaw_indices(c_lines, groundtruth[idx])\n",
    "        if len(flaw_indices) < 1:\n",
    "            continue\n",
    "\n",
    "        object_file = pickle.load(gzip.open(name))\n",
    "        data = Data(x=torch.cat((object_file[\"astenc\"], object_file[\"codeenc\"]), dim=1), edge_index=object_file[\"edge_index\"], y=object_file[\"y\"])\n",
    "        data.edge_index = data.edge_index.long()\n",
    "        data.x = data.x.float()\n",
    "        c_logs, o_logs, co_logs = model(data)\n",
    "\n",
    "        edge_c, edge_t, node_c, node_t = model.layer.explain(data)\n",
    "        node_mask = node_c.sigmoid()\n",
    "\n",
    "        linescores = defaultdict(int)\n",
    "        for node_idx, score in enumerate(node_mask):\n",
    "            if \":\" not in object_file[\"lines\"][node_idx]:\n",
    "                continue\n",
    "            lower = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[0].replace(\"\\\"\",\"\"))\n",
    "            upper = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[1].replace(\"\\\"\",\"\"))\n",
    "            lines = list(range(int(lower), int(upper)+1))\n",
    "            for line in lines:\n",
    "                linescores[line] += score/len(lines)\n",
    "        lines = [0 for _ in range(max(linescores.keys()))]\n",
    "        for line, score in linescores.items():\n",
    "            lines[line-1] = score\n",
    "        \n",
    "        sorted_lines = sort_lines(lines)\n",
    "        rank = min_rank_of_indices(sorted_lines, flaw_indices)\n",
    "        ranks.append(rank)\n",
    "    ranks = torch.as_tensor(ranks)\n",
    "    ranks = ranks[ranks.isfinite()]\n",
    "    def topk_acc(k):\n",
    "            return round((\n",
    "                torch.sum(ranks < k) / len(ranks)\n",
    "            ).item() * 100, 2)\n",
    "    print({\n",
    "        \"Top1-Acc\": topk_acc(1),\n",
    "        \"Top3-Acc\": topk_acc(3),\n",
    "        \"Top5-Acc\": topk_acc(5),\n",
    "    })\n",
    "    \"\"\"print({\n",
    "        \"Top1-Acc\": torch.sum(ranks < 1) / len(ranks),\n",
    "        \"Top5-Acc\": torch.sum(ranks < 5) / len(ranks),\n",
    "        \"Top10-Acc\": torch.sum(ranks < 10) / len(ranks),\n",
    "        \"Top100-Acc\": torch.sum(ranks < 100) / len(ranks),\n",
    "        \"IFA\": torch.mean(ranks.float()),\n",
    "        \"Count\": len(ranks),\n",
    "    })\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_TEST\n",
      "{'Top1-Acc': 43.65, 'Top3-Acc': 58.01, 'Top5-Acc': 68.51}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_TEST\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_CHROMIUM\n",
      "{'Top1-Acc': 43.65, 'Top3-Acc': 57.46, 'Top5-Acc': 69.06}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_CHROMIUM\", \"apply_codestyle_Chromium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_MOZILLA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Top1-Acc': 42.54, 'Top3-Acc': 58.56, 'Top5-Acc': 69.61}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_MOZILLA\", \"apply_codestyle_Mozilla\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_GOOGLE\n",
      "{'Top1-Acc': 44.2, 'Top3-Acc': 60.77, 'Top5-Acc': 70.72}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_GOOGLE\", \"apply_codestyle_Google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_LLVM\n",
      "{'Top1-Acc': 44.2, 'Top3-Acc': 58.56, 'Top5-Acc': 69.61}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_LLVM\", \"apply_codestyle_LLVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LINEVUL_GNU\n",
      "{'Top1-Acc': 39.78, 'Top3-Acc': 56.35, 'Top5-Acc': 67.96}\n"
     ]
    }
   ],
   "source": [
    "eval_linelevel_merged(\"LINEVUL_GNU\", \"apply_codestyle_GNU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHP_FUNCTION(imageconvolution)\n",
      "{\n",
      "zval *SIM, *hash_matrix;\n",
      "zval **var = NULL, **var2 = NULL;\n",
      "gdImagePtr im_src = NULL;\n",
      "double div, offset;\n",
      "int nelem, i, j, res;\n",
      "float matrix[3][3] = {{0,0,0}, {0,0,0}, {0,0,0}};\n",
      "\n",
      "if (zend_parse_parameters(ZEND_NUM_ARGS() TSRMLS_CC, \"radd\", &SIM, &hash_matrix, &div, &offset) == FAILURE) {\n",
      "RETURN_FALSE;\n",
      "}\n",
      "\n",
      "ZEND_FETCH_RESOURCE(im_src, gdImagePtr, &SIM, -1, \"Image\", le_gd);\n",
      "\n",
      "nelem = zend_hash_num_elements(Z_ARRVAL_P(hash_matrix));\n",
      "if (nelem != 3) {\n",
      "php_error_docref(NULL TSRMLS_CC, E_WARNING, \"You must have 3x3 array\");\n",
      "RETURN_FALSE;\n",
      "}\n",
      "\n",
      "for (i=0; i<3; i++) {\n",
      "if (zend_hash_index_find(Z_ARRVAL_P(hash_matrix), (i), (void **) &var) == SUCCESS && Z_TYPE_PP(var) == IS_ARRAY) {\n",
      "if (Z_TYPE_PP(var) != IS_ARRAY || zend_hash_num_elements(Z_ARRVAL_PP(var)) != 3 ) {\n",
      "php_error_docref(NULL TSRMLS_CC, E_WARNING, \"You must have 3x3 array\");\n",
      "RETURN_FALSE;\n",
      "}\n",
      "\n",
      "for (j=0; j<3; j++) {\n",
      "if (zend_hash_index_find(Z_ARRVAL_PP(var), (j), (void **) &var2) == SUCCESS) {\n",
      "\t\t\t\t\tSEPARATE_ZVAL(var2);\n",
      "\t\t\t\t\tconvert_to_double(*var2);\n",
      "\t\t\t\t\tmatrix[i][j] = (float)Z_DVAL_PP(var2);\n",
      "} else {\n",
      "php_error_docref(NULL TSRMLS_CC, E_WARNING, \"You must have a 3x3 matrix\");\n",
      "RETURN_FALSE;\n",
      "}\n",
      "}\n",
      "}\n",
      "}\n",
      "res = gdImageConvolution(im_src, matrix, (float)div, (float)offset);\n",
      "\n",
      "if (res) {\n",
      "RETURN_TRUE;\n",
      "} else {\n",
      "RETURN_FALSE;\n",
      "}\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\".join(get_c_lines(\"179598\", \"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linescores_for(index, CPG_SET=\"LINEVUL_TEST\", C_SET=\"test\"):\n",
    "    c_lines = get_c_lines(index, C_SET)\n",
    "\n",
    "    object_file = pickle.load(gzip.open(f\"../cache/{CPG_SET}/{index}_1.cpg.pt.gz\"))\n",
    "    data = Data(x=torch.cat((object_file[\"astenc\"], object_file[\"codeenc\"]), dim=1), edge_index=object_file[\"edge_index\"], y=object_file[\"y\"])\n",
    "    data.edge_index = data.edge_index.long()\n",
    "    data.x = data.x.float()\n",
    "    c_logs, o_logs, co_logs = model(data)\n",
    "\n",
    "    edge_c, edge_t, node_c, node_t = model.layer.explain(data)\n",
    "    node_mask = node_t.sigmoid()\n",
    "\n",
    "    linescores = defaultdict(int)\n",
    "    for node_idx, score in enumerate(node_mask):\n",
    "        if \":\" not in object_file[\"lines\"][node_idx]:\n",
    "            continue\n",
    "        lower = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[0].replace(\"\\\"\",\"\"))\n",
    "        upper = int(object_file[\"lines\"][node_idx].split(\" \")[0].split(\":\")[1].replace(\"\\\"\",\"\"))\n",
    "        lines = list(range(int(lower), int(upper)+1))\n",
    "        for line in lines:\n",
    "            linescores[line] += score/len(lines)\n",
    "    lines = [0 for _ in range(max(linescores.keys()))]\n",
    "    for line, score in linescores.items():\n",
    "        lines[line-1] = score\n",
    "    \n",
    "    sorted_lines = sort_lines(lines)\n",
    "    print(\"Sorted lines\", sorted_lines)\n",
    "    print(\"Line scores\", dict((k, v.item()) for k,v in linescores.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted lines [7, 22, 32, 13, 40, 23, 28, 29, 21, 6, 3, 15, 31, 16, 2, 5, 4, 30, 35, 10, 34, 9, 42, 25, 24, 18, 45, 43, 17, 33, 44, 36, 0, 26, 11, 46, 19, 37, 27, 38, 39, 47, 41, 20, 14, 12, 8, 1]\n",
      "Line scores {1: 0.5813077688217163, 2: 0.03078407049179077, 3: 2.2228031158447266, 4: 3.6467161178588867, 5: 2.2121074199676514, 6: 2.222046136856079, 7: 3.685823917388916, 8: 10.996650695800781, 9: 0.03078407049179077, 10: 1.1479395627975464, 11: 1.1654982566833496, 12: 0.504533052444458, 13: 0.03078407049179077, 14: 6.467837810516357, 15: 0.03078407049179077, 16: 3.2387633323669434, 17: 2.242281436920166, 18: 0.9080506563186646, 19: 0.9932812452316284, 20: 0.37688708305358887, 21: 0.03078407049179077, 22: 5.808654308319092, 23: 8.294575691223145, 24: 6.1823272705078125, 25: 1.0354623794555664, 26: 1.0578889846801758, 27: 0.5061697959899902, 28: 0.19199636578559875, 29: 6.01950216293335, 30: 5.941442012786865, 31: 1.8142070770263672, 32: 2.3964335918426514, 33: 6.480062007904053, 34: 0.7410187721252441, 35: 1.1502563953399658, 36: 1.2214149236679077, 37: 0.5988960862159729, 38: 0.33793359994888306, 39: 0.19199636578559875, 40: 0.10766114294528961, 41: 6.29960298538208, 42: 0.03078407049179077, 43: 1.072956919670105, 44: 0.9634020924568176, 45: 0.6021031737327576, 46: 0.9634020924568176, 47: 0.3890240788459778, 48: 0.03078407049179077}\n"
     ]
    }
   ],
   "source": [
    "linescores_for(\"179598\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "dff5fd2a8179060ff25b3eeeaed448bc9a2dfe4438c9b63d106cffbef4e81482"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
